üç± Food Vision ‚Äî EfficientNetB0 (Adam vs Lion Optimizer)
A deep learning project focused on food image classification using transfer learning with EfficientNetB0.
The model was trained and fine-tuned on the Food101 dataset to compare the performance of two modern optimizers ‚Äî Adam and Lion ‚Äî in improving model convergence and accuracy.
________________________________________
üß† Project Overview
This project explores the use of EfficientNetB0, a lightweight yet powerful convolutional neural network, for classifying 101 types of food images.
The training was performed in two phases ‚Äî Feature Extraction and Fine-Tuning ‚Äî to balance generalization, stability, and performance.
The experiments were conducted using:
‚Ä¢	TensorFlow / Keras
‚Ä¢	Food101 dataset (via TensorFlow Datasets)
‚Ä¢	Input Size: 224√ó224 pixels
‚Ä¢	Callbacks: TensorBoard, ModelCheckpoint, ReduceLROnPlateau
________________________________________
‚öôÔ∏è Training Pipeline

| Phase                  | Description                                                   | Epochs | Learning Rate  | Layers Trained |
| ---------------------- | ------------------------------------------------------------- | ------ | -------------- | -------------- |
| **Feature Extraction** | Trained only top dense layers with frozen EfficientNetB0 base | 10     | 0.001 ‚Üí 0.0005 | Top Layers     |
| **Fine-Tuning**        | Unfroze last 50 layers for domain-specific adaptation         | 8‚Äì10   | 1e-5           | Last 50 Layers |

________________________________________
‚ö° Model Configurations
üß© Model 1 ‚Äî EfficientNetB0 + Adam Optimizer
Objective: Build a stable and high-performing food classifier through feature extraction and controlled fine-tuning.
Results:

| Phase              | Train Acc | Val Acc  | Val Loss |
| ------------------ | --------- | -------- | -------- |
| Feature Extraction | 0.55      | 0.69     | 1.13     |
| Fine-Tuning        | 0.63      | 0.74     | 0.93     |
| Final              | 0.66      | **0.75** | **0.87** |

‚úÖ Final Test Accuracy: ~75.5%
üíæ Model Path: /models/food_vision_final_adam_model.keras
Key Takeaways:
‚Ä¢	Adam‚Äôs adaptive learning ensured smooth and stable convergence.
‚Ä¢	Feature extraction built a strong general base.
‚Ä¢	Fine-tuning refined class-specific textures and boosted validation accuracy.
________________________________________
ü¶Å Model 2 ‚Äî EfficientNetB0 + Lion Optimizer
Objective: Evaluate the newly introduced Lion optimizer for efficient convergence and improved accuracy.
Results:

| Phase                     | Train Accuracy | Val Accuracy | Val Loss |
| :------------------------ | :------------: | :----------: | :------: |
| Feature Extraction        |      0.51      |     0.66     |   1.54   |
| Fine-Tuning (Epoch 10‚Äì18) |      0.74      |     0.79     |   0.79   |
| **Final (Epoch 20)**      |    **0.77**    |   **0.80**   | **0.78** |

‚úÖ Final Test Accuracy: ~79%
üíæ Model Path: /models/food_vision_final_lion_model.keras
Key Takeaways:
‚Ä¢	Lion optimizer provided smoother updates with less oscillation.
‚Ä¢	Gradual unfreezing avoided overfitting and preserved pretrained knowledge.
‚Ä¢	Achieved ~4% higher accuracy than Adam on the same configuration.
________________________________________
üìä Comparative Summary

| Optimizer | Final Val Accuracy | Test Accuracy | Test Loss | Remarks                      |
| --------- | ------------------ | ------------- | --------- | ---------------------------- |
| **Adam**  | ~75%               | 75.5%         | 0.88      | Stable and well-generalized  |
| **Lion**  | **~79%**           | **79%**       | **0.78**  | Faster, smoother convergence |

üîπ Winner: Lion Optimizer ‚Äî achieved higher accuracy and lower loss with the same architecture and dataset.
________________________________________
üß™ Key Insights
‚Ä¢	Transfer learning with gradual layer unfreezing significantly boosts performance.
‚Ä¢	Both Adam and Lion optimizers perform well, but Lion offers superior fine-tuning stability.
‚Ä¢	EfficientNetB0 remains an excellent backbone for medium-sized image datasets like Food101.
________________________________________
üöÄ Tools & Libraries
‚Ä¢	TensorFlow / Keras
‚Ä¢	TensorFlow Datasets (TFDS)
‚Ä¢	NumPy, Matplotlib
‚Ä¢	TensorBoard for experiment tracking
‚Ä¢	Google Colab + Drive for training and model storage
________________________________________
üèÅ Conclusion
The EfficientNetB0 + Lion optimizer configuration delivered the best performance on the Food101 dataset, achieving ~79% test accuracy with robust generalization.
This experiment highlights the importance of optimizer selection and staged fine-tuning in transfer learning workflows.

